\chapter{Evaluierung}

Die Qualität der Ergebnisse des in der Implementierung realisierten Modells wird in diesem Kapitel durch ein Testexperiment überprüft. Weiterhin werden Ausführungszeiten für beispielsweise verschieden große $k$ beim Bag of Visual Words betrachtet, um eine Einsicht in die Performance der Algorithmen zu gewinnen.
Im Kapitel Experimentaufbau wird zunächst das Experiement sowie verwendete Metriken und Ergebnistypen behandelt. Nachfolgend wird erläutert, wie die großen Menge an benötigten Trainings- und Testdaten wiederholbar und automatisiert aufgebaut wird. Dieser Abschnitt illustriert auch, wie eine Durchführung des Experiments vonstatten geht. Im letzten Teil werden dann konkrete Testgruppen aus den Caltech101 \cite{cal2004} Bilddaten erzeugt. Diese Menge an Bilddaten hat große Verbreitung im Bereich der Objekterkennung gefunden. Auf diese Weise ist ein Vergleich mit Arbeiten Anderer prinzipiell möglich.

\section{Testdaten und Testgenerierung}

Der Abschnitt Testdaten stellt die hier verwendete Menge von Bildern vor, die Caltech101, welche extra für den Test von Algorithmen bezüglich der Objekterkennung in Bildern entwickelt wurde.\newline
Im folgenden Abschnitt zur Testgenerierung wird ein Verfahren zur zufälligen Auswahl von Trainings- und Testbildern unter Berücksichtigung verschiedener Restriktionen, wie z.B. dem Verhältnis der Anzahl von Trainings- zu Testbildern vorgestellt.

\subsection{Testdaten}

Als Testmenge wurden die Bilder der Caltech101-Menge verwendet. Bei Caltech101 handelt es sich um eine weit verbreitete Menge von Bilddaten, die vorwiegend zum Test von Algorithmen bezüglich der Objekterkennung in Bildern dient. Insgesamt liegen, wie der Name sagt, 101 Kategorien vor, die jeweils zwischen 40 und 800 Bildern enthalten. Auf der offiziellen Webseite \footnote{http://www.vision.caltech.edu/Image\textunderscore Datasets/Caltech101/} und im Artikel der Autoren wird empfohlen, die eigene Arbeit mit derer anderen vergleichbar zu halten, indem:

\begin{itemize}
	\item Eine feste Anzahl an Trainings- und Testbildern verwendet wird.
	\item Experimente mit einer zufälligen Auswahl an Bildern wiederholt werden.
	\item Ähnlich viele Bilder, wie in den Arbeiten anderer, verwendet werden (1, 3, 5, 10, 15, 20 oder 30 Trainingsbilder; 20 oder 30 Testbilder).
\end{itemize}

Die Caltech101 Daten liegen nach Download kategorisiert im JPG-Format vor. Die Struktur wurde so beibehalten und ist noch für die Testgenerierung relevant. Direkt unter dem Caltech101-Ordner ist pro Kategorie ein Ordner vorhanden, der die jeweiligen Bilder immer im gleichen Namensschema enthält:\newline

\dirtree{%src
.1 Caltech101.
.2 accordion.
.3 image\textunderscore 0001.jpg.
.3 image\textunderscore 0002.jpg.
.3 ....
.2 airplanes.
.3 ....
.2 ....
}

Abbildung \ref{img:strawberries} zeigt vier Bilder aus der Kategorie \enquote{Erdbeere}. Neben Bildern von realen Rosengewächsen sind auch Zeichnungen und Objekte enthalten, die Form und Farbe der Erdbeere nachempfunden sind. Auch sind die Objekte auf einem Bild zum Teil in unterschiedlicher Menge vorhanden. Durch diese Variation ist ein Algorithmus so gefordert, tatsächlich eine Abstraktion zu lernen.

\begin{figure}
	\centering
	\includegraphics[scale=0.5]{images/strawberry.png}
	\caption{Verschiedene Bilder aus der Kategorie \enquote{Erdbeere} der Caltech101 Bilddaten.}
	\label{img:strawberries}
\end{figure}

\subsection{Testgenerierung}

Die Generierung von Testdaten bietet sich aus mehreren Gründen an. Zum einen sind enorm viele Trainingsdaten notwendig, um ein leistungsfähiges Modell zu generieren, zum anderen sollen im Test ca. 2000 Bildpaare verwendet werden. Ein manueller Testaufbau wäre fehleranfällig und nicht sehr flexibel. Da ein praktisch taugliches Modell erst durch die Variation einiger Parameter gefunden werden kann, ist es wünschenswert, Testdaten mit verschiedenen Eigenschaften generieren zu können:

\begin{itemize}
	\item Die Anzahl der Kategorien sollte bestimmbar sein. Dies entspricht einer Kategorie der Caltech101-Daten. Somit sind hier theoretisch bis zu 101 Kategorien im Test denkbar.
	\item Das Verhältnis bzw. die Anzahl an Trainings- und Testbildern muss definierbar sein.
\end{itemize}

Letztendlich sollen die Histogramme der \textit{Visual Words} zweier Bilder miteinander verglichen und so die Ähnlichkeit gemessen werden. Ein Programm automatisiert daher die Generierung solcher Paare: Es werden zufällige Bildpaare aus ausgewählten Kategorien (\textit{airplanes}, \textit{anchor}, ...) selektiert. Diese Paare, sowie die Information, ob die Bilder in der selben oder einer verschiedenen Kategorie liegen, stellen einen Testkandidaten dar. Zwei Bilder liegen dabei in der selben Klasse, wenn sie im selben Ordner im Dateisystem, also hier im Caltech101-Ordner, enthalten sind. Das Ergebnis wird dann als Datei \textit{test \textunderscore time.txt} gespeichert. Die Pfade der Bilder werden hierbei relativ zum Caltech101-Ordner gespeichert, die Information über die Kategorie wird als \enquote{+} bzw. \enquote{-} kodiert. Eine Datei für die Kategorien \textit{airplanes} und \textit{anchor} könnte dann so beginnen:\newline

\begin{lstlisting}
airplanes/image_0023.jpg airplanes/image_0009.jpg +
airplanes/image_0002.jpg anchor/image_0015.jpg -
anchor/image_0013.jpg airplanes/image_0002.jpg -
anchor/image_0001.jpg anchor/image_0005.jpg +
airplanes/image_0006.jpg anchor/image_0006.jpg -
...
\end{lstlisting}

Neben den zu verwendenden Kategorien muss bei Erzeugung die Anzahl der Testkandidaten, das Verhältnis von positiven zu negativen Kategorien sowie die Anzahl der Trainings- und Testbilder angegeben werden. \newline
Die Bilder, welche durch das Programm für das Training ausgewählt wurden, werden separat als \textit{train\textunderscore time.txt} gespeichert. Pro Zeile ist hier der relative Pfad des Bildes innerhalb des Caltech101-Ordners enthalten.

\section{Experimentaufbau}

Das Experiment soll sowohl die Feature-Kompression durch einen Autoencoder testen als auch die Kategorisierung bzw. den Vergleich der Bilder durch den Bag of Visual Words. Aus diesem Grund ist das Experiment zweigeteilt: 

\begin{enumerate}[(a)]%
	\item In dieser Variante findet ein reiner Test des Bag of Visual Words statt. Hierfür werden durch SIFT die Feature-Deskriptoren von Trainingsbildern extrahiert und direkt als Eingabe an den Bag of Visual Words gegeben. Anschließend folgt die Verarbeitung der Testbilder.
	\item Hier wird nach Extraktion der \textit{keypoints} durch den SIFT-Detektor der Feature-Deskriptor durch den Autoencoder erzeugt. Die so erhaltenen Features werden dann wie in (a) durch den Bag of Visual Words gruppiert und anschließend die \textit{Visual Words} der Testbilder erzeugt.
\end{enumerate}

Wichtig ist, dass pro Durchführung des Experiments in beiden Varianten die gleichen Trainings- und Testbilder verwendet werden, damit die Ergebnisse beider Deskriptoren miteinander vergleichbar sind. \newline
Nach Erzeugung des Modells mit den Trainingsbildern, werden nun die Features der Testkandidaten extrahiert und pro Bild dies \textit{Visual Words} berechnet. Die Ähnlichkeit \textit{sim (similarity)} der resultierenden Histogramme $h_1$ und $h_2$ wird dann als 1 $-$ \textit{MSE (mean squared error)} gemessen:

$$sim(h_1, h_2) = 1 - MSE(h_1, h_2)$$
$$MSE(h_1, h_2) = \frac{1}{n}\sum_{i=0}^{n}(h_{1_i} - h_{2_i})^{2}$$

Beträgt die Ähnlichkeit von zwei Histogrammen 1 werden sie als identisch angesehen. Werte nahe 0 drücken aus, dass die Histogramme sich sehr voneinander unterscheiden. Damit nun unterschieden werden kann, ob zwei Bilder in derselben Klasse sind, muss die Ähnlichkeit mit einem Schwellwert verglichen werden. So kann beispielsweise definiert werden, dass es sich bei einer Ähnlichkeit größer als $0.8$ um dieselbe Klasse handelt. Somit hat der Schwellwert unmittelbar Auswirkungen auf die Ergebnisse und sollte selbst Bestandteil des Experiments sein. Das Resultat eines solchen Vergleichs ist dann einer der beiden folgenden Kategorien zuzuordnen:

\begin{itemize}
	\item \textbf{True Positives} Bei \textit{True Positives} handelt es sich um zwei Bildern die entweder in der gleichen oder einer verschiedenen Klasse liegen und die Vorhersage des Modells diesbezüglich korrekt ist.
	\item \textbf{False Positives} In diesem Fall ist die Klassifizierung durch das Modell nicht korrekt: Bei gleicher Klasse wurde eine geringe Ähnlichkeit erkannt, bei verschiedenen eine Hohe.
\end{itemize}

Damit ein Modell zuverlässige Ergebnisse liefert, muss es größtenteils \textit{True Positives} erkennen, bzw. der Anteil der \textit{True Positives} sollte im Verhältnis zu den \textit{False Positives} bei weitem überwiegen. Für eine visuelle Darstellung dieses Verhältnisses eignet sich die \textit{Receiver Operating Characteristic (ROC)}: Diese stellt die \textit{True Positives} auf der Ordinate und die \textit{False-Positives} auf der Abzisse dar.

\section{Experimentdurchführung}

Das Clustering wurde in drei Experimenten getestet. Pro Experiment wurden Eigenschaften einer Bildmenge variiert, um zu beobachten, wie sich diese Veränderungen auf die Qualität der Ergebnisse auswirkt. Die Testmengen sind jeweils wie folgt gewählt:

\begin{itemize}
	\item \textbf{Test 1} besteht aus zwei Kategorien: \enquote{Bonsai} und \enquote{Leopard}. Es wurden \todo{x} Bilder verwendet, aus beiden Kategorien je \todo{x/2}. Von diesen Bildern sind 30\% für die Trainings- und die anderen 70\% für die Testphase bestimmt. Insgesamt liegen im Training ca. $41.000$ Features vor, ähnlich viele wie in Zhaos Experiment (dort ca. $40.000$).
	\item \textbf{Test 2} enthält ebenfalls, wie Test 1, die Kategorien \enquote{Bonsai} und \enquote{Leopard}. Hier werden aber insgesamt \todo{2x} Bilder verwendet. Aus beiden Kategorien wurden wieder gleich viele Bilder gewählt und die Aufteilung in Trainings- bzw. Testdaten bleibt auch gleich. Durch SIFT wurden hier für das Training ca. $77.000$ Features ermittelt, also nicht ganz doppelt so viele wie in Test 1.
	\item \textbf{Test 3} enthält drei Kategorien von Bildern, um zu testen, ob eine komplexere Kategorisierung prinzipiell möglich ist. Als Kategorien wurden hier \enquote{Flugzeug}, \enquote{Motorrad} und \enquote{Armbanduhr} gewählt. Insgesamt werden \todo{y} viele Bilder verwendet, jede Kategorie steuert ein Drittel der Bilder bei. Die Aufteilung in Trainings- und Testdaten wird auch hier beibehalten. In der Trainingsphase lagen \todo{z} Features vor.
\end{itemize} 

\begin{table}
    \hfill
    \begin{tabular}[t]{ | r | c | c |}
    \hline
	     & SIFT & AE \\ \hline    
    5    & 0.00 & 0.00 \\ \hline
    10   & 0.00 & 0.00 \\ \hline
    20   & 0.00 & 0.00 \\ \hline
    50   & 0.00 & 0.00 \\ \hline
    100  & 0.00 & 0.00 \\ \hline
	250  & 0.00 & 0.00 \\ \hline
	500  & 0.00 & 0.00 \\ \hline
	1000 & 0.00 & 0.00 \\ \hline  
    \end{tabular}
    \hfill
    \begin{tabular}[t]{ | r | c | c |}
    \hline
	     & SIFT & AE \\ \hline    
    5    & 0.00 & 0.00 \\ \hline
    10   & 0.00 & 0.00 \\ \hline
    20   & 0.00 & 0.00 \\ \hline
    50   & 0.00 & 0.00 \\ \hline
    100  & 0.00 & 0.00 \\ \hline
	250  & 0.00 & 0.00 \\ \hline
	500  & 0.00 & 0.00 \\ \hline
	1000 & 0.00 & 0.00 \\ \hline    
    \end{tabular}
    \hfill
    \begin{tabular}[t]{ | r | c | c |}
    \hline
	     & SIFT & AE \\ \hline    
    5    & 0.00 & 0.00 \\ \hline
    10   & 0.00 & 0.00 \\ \hline
    20   & 0.00 & 0.00 \\ \hline
    50   & 0.00 & 0.00 \\ \hline
    100  & 0.00 & 0.00 \\ \hline
	250  & 0.00 & 0.00 \\ \hline
	500  & 0.00 & 0.00 \\ \hline
	1000 & 0.00 & 0.00 \\ \hline    
    \end{tabular}
    \hfill
	\caption{Laufzeiten der \textit{global memory} Implementierung des Bag of Visual Words. Von links nach rechts ist Test 1 bis 3 aufgelistet.}
\end{table}

\begin{table}
    \hfill
    \begin{tabular}[t]{ | r | c | c |}
    \hline
	     & SIFT & AE \\ \hline    
    5    & 0.00 & 0.00 \\ \hline
    10   & 0.00 & 0.00 \\ \hline
    20   & 0.00 & 0.00 \\ \hline
    50   & 0.00 & 0.00 \\ \hline
    90   & 0.00 & 0.00 \\ \hline
	200  & -    & 0.00 \\ \hline
	300  & -    & 0.00 \\ \hline    
    \end{tabular}
    \hfill
    \begin{tabular}[t]{ | r | c | c |}
    \hline
	     & SIFT & AE \\ \hline    
    5    & 0.00 & 0.00 \\ \hline
    10   & 0.00 & 0.00 \\ \hline
    20   & 0.00 & 0.00 \\ \hline
    50   & 0.00 & 0.00 \\ \hline
    90   & 0.00 & 0.00 \\ \hline
	200  & -    & 0.00 \\ \hline
	300  & -    & 0.00 \\ \hline
	\end{tabular}
    \hfill
    \begin{tabular}[t]{ | r | c | c |}
    \hline
	     & SIFT & AE \\ \hline    
    5    & 0.00 & 0.00 \\ \hline
    10   & 0.00 & 0.00 \\ \hline
    20   & 0.00 & 0.00 \\ \hline
    50   & 0.00 & 0.00 \\ \hline
    90   & 0.00 & 0.00 \\ \hline
	200  & -    & 0.00 \\ \hline
	300  & -    & 0.00 \\ \hline
	\end{tabular}
    \hfill
	\caption{Laufzeiten der \textit{shared memory} Implementierung des Bag of Visual Words. Von links nach rechts ist Test 1 bis 3 aufgelistet.}
\end{table}
\chapter{Fazit und Ausblick}

In dieser Arbeit wurde demonstriert, wie ein Gruppieren von Bilddaten mittels unüber- wachter Lernverfahren realisiert werden kann. Um den großen Datenmengen gerecht zu werden und eine annehmbare Ausführungszeit zu erzielen, wurde das Modell auf eine parallele Verarbeitung durch Nvidia Grafikkarten ausgelegt. Für die Gruppierung der Features wurden zwei Ansätze getestet: Zum einen ein Clustering auf Basis von SIFT-Features, zum anderen auf Basis von Features, die durch einen Autoencoder komprimiert wurden. In drei Experimenten wurde getestet, wie erfolgreich eine Klassifizierung von Bildern durch diese Features durchgeführt werden kann. Mit knapp $70$\% in allen drei Experimenten, liefert SIFT hier deutlich bessere Ergebnisse als die Autoencoder-Features (zwischen $60$\% und $63$\%). Erfolgreich ist die Klassifizierung letztendlich nicht: Knapp jedes dritte Bild würde falsch kategorisiert werden.\newline
Das aktuelle Modell besitzt viele Parameter und bietet somit eine Vielzahl an weiteren Möglichkeiten, die getestet werden können. Beim Autoencoder kann die Anzahl an der Iterationen im Training oder die Lernrate variiert werden, um den Einfluss auf die Ergebnisse zu beobachten. Beim Bag of Visual Words kann ebenfalls die Anzahl an Trainingsiterationen sowie der Wert für das Konvergenzkriterum angepasst werden. Außerdem kann studiert werden, wie sich die Ergebnisse der Klassifizierung verändern, wenn als Schwellwert für eine positive Klassifizierung andere Werte als $0.8$ verwendet werden.\newline
Der aktuelle Stand der Implementierung dient als \textit{Proof of Concept}. Um eine praktische Verwendung zu ermöglichen, sollte der \enquote{technische Bruch} beseitigt werden: Aktuell findet die Kompression der Daten durch TensorFlow statt, das Clustering hingegen ist in CUDA C geschrieben. Eine reine TensorFlow oder CUDA Implementierung ist nicht nur leichter zu überschauen und zu warten, sondern kann auch unnötige Datentransfers eliminieren. Hier ist zu erwarten, dass eine Umsetzung in TensorFlow weniger komplex ist als in CUDA. CUDA hingegeben bietet mehr Möglichkeiten zur Optimierung, um den Algorithmus zu beschleunigen. Momentan ist die \textit{shared memory} Implementierung abhängig von der Anzahl der Cluster $k$. Um dies zu umgehen, kann ein Mechanismus zum Laden der Daten in Gruppen (\textit{chunks}) implementiert werden: Ist nicht genug \textit{shared memory} vorhanden, werden die Daten in \textit{chunks} eingeteilt und nacheinander verarbeitet.
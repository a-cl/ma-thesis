\chapter{Ausblick}

In dieser Arbeit wurde demonstriert, wie ein Gruppieren von Bilddaten mittels unüber- wachter Lernverfahren realisiert werden kann. Um den großen Datenmengen gerecht zu werden und eine annehmbare Ausführungszeit zu erzielen, wurde das Modell auf eine parallele Verarbeitung durch Nvidia Grafikkarten ausgelegt. Der aktuelle Stand der Implementierung dient als \textit{Proof of Concept}. Um eine praktische Verwendung zu ermöglichen, sollte der \enquote{technische Bruch} beseitigt werden: Aktuell findet die Kompression der Daten durch TensorFlow statt, das Clustering hingegen ist in CUDA C geschrieben. Eine reine TensorFlow oder CUDA Implementierung ist nicht nur leichter zu überschauen und zu warten, sondern kann auch unnötige Datentransfers eliminieren. ier ist zu erwarten, dass eine Umsetzung in TensorFlow weniger komplex ist als in CUDA. CUDA hingegeben bietet mehr Möglichkeiten zur Optimierung, um den Algorithmus zu beschleunigen. Momentan ist die \textit{shared memory} Implementierung abhängig von der Anzahl der Cluster $k$. Um dies zu umgehen, kann ein Mechanismus zum Laden der Daten in Gruppen (\textit{chunks}) implementiert werden: Ist nicht genug \textit{shared memory} vorhanden, werden die Daten in \textit{chunks} eingeteilt und nacheinander verarbeitet.
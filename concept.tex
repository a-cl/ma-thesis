\chapter{Konzept}

Das Kapitel Konzeption beschäftigt sich zunächst mit dem Prozess der Feature Extraktion. Hierfür wird der SIFT Algorithmus nach Lowe genutzt. Darauf aufbauend werden zwei Verfahren vorgestellt, das Bag of Visual Words Modell und der Autoencoder, die anhand von SIFT Deskriptoren eine Klassifizierung von Bildern ermöglichen.

\begin{enumerate}
	\item Verarbeitung der bestehenden Bilder
	\item Auswahl der Features
	\item Layer des Netzes, Stacking, Denoising ?
	\item Skizzierung des Gesamtsystems \begin{enumerate}
		\item Datenbank einlesen, Feature Extraction, Autoencoder Training
		\item Bild eingeben, Feature Extraction, Autoencoder Klassifizierung
		\item Trainieren des Netzes?
	\end{enumerate}		
	
\end{enumerate}

Als Basis der Klassifizierung werden SIFT Feature Deskriptoren verwendet. Es ist beim Einsatz von SIFT zu beachten, dass es sich um einen patentierten Algorithmus handelt. Der SIFT Deskriptor enthält 128 Dimensionen und ist so für einen Vergleich nur schwer geeignet, da pro Bild ca. 100 bis 1000 Feature Vektoren generiert werden. Es werden daher im folgenden zwei Ansätze vorgestellt, die die Dimensionalität der Features reduzieren und eine durch Grafikkarten gestützte Berechnung von ähnlichen Bildern ermöglichen.

\section{Feature Extraktion}

Die Extraktion der Features eines Bildes erfolgt zu Beginn beider Anwendungsfälle. Im Anwendungsfall Bild speichern werden die Features zur Speicherung gewonnen. Diese werden mit den Features des Anwendungsfalles Bild suchen verglichen. Die Extraktion erwartet als Eingabe den Pfad zu einer Bilddatei im JPEG oder PNG Format und liefert als Rückgabe eine Liste der gefundenen Features.  Als Verfahren zur Extraktion kann zwischen SIFT und TODO gewählt werden. Je nach gewähltem Verfahren variiert die Struktur der Features.

\section{Bag of Visual Words}

Das Bag of Visual Words Modell ist im Grunde ein Histogramm, dass die Häufigkeitsverteilung von gefundenen Codewords abbildet. Sobald also das Codebook und die Codewords generiert wurden, kann durch einen Histogramm Algorithmus die Berechnung erfolgen. Im Grundlagen Kapitel wurde vorgestellt, wie sich ein Histogramm parallel auf Nvidia Grafikkarten berechnen lässt. Zum generieren des Codebooks ist eine Trainingsphase notwendig. Es muss eine Menge an Featurevektoren geclustert werden 

TODO: zusätzliche Dimensionen nutzen?
TODO: Block / Gridsize -> Größe Featurevektor (128 dim)
TODO: Training

\section{Aufbau des Autoencoders}

In diesem Ansatz werden zur Reduzierung der Dimensionen der Feature-Vektoren ein Stacked Denoising Autoencoder verwendet. Die Anzahl der Neuronen in der Eingabeschicht entspricht hierbei den Dimensionen des Feature-Vektors. Im Fall eines SIFT-Features würden so in der Eingabeschicht 3096 Neuronen vorhanden sein, da ein Feature 128 Dimensionen enthält und eine 24 $\times$ 24 Nachbarschaft von Punkten betrachtet wird. Die Anzahl der Neuronen in der Ausgabeschicht entspricht denen der Eingabeschicht, denn eben diese bildet das rekonstruierte Feature ab. Um die Anzahl der Dimensionen der Features schrittweise zu reduzieren, werden Stacked Autoencoder verwendet. Jede Schicht im Encoder enthält weniger Neuronen als die vorige. Der Decoder ist umgekehrt aufgebaut, um aus der komprimierten Darstellung das Feature wieder zu gewinnen. Die einzelnen Autoencoder, die später hintereinander geschaltet werden, müssen einzeln trainiert werden.
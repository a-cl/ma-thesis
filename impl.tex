\chapter{Implementierung}

Die Implementierung beschäftigt sich mit den Details zur Umsetzung der Feature Extraktion, sowie des Bag of Visual Words und Autoencoders.

\section{Feature Extraktion}

Zur Extraktion der Features wird die OpenCV SIFT Implementierung verwendet. Zur Verwendung von SIFT, ist es erforderlich das opencv Projekt zusammen mit dem opencv-contrib Projekt selbst zu kompilieren. Bei SIFT handelt es sich um einen patentierten Algorithmus, daher ist er seit Version 3.0 nicht mehr standardmäßig im opencv Projekt enthalten [REF]. Zu Gewinnung der keypoints eines Bildes, muss ein neuen SIFT Detektor erstellt und die detect Methode mit einem Bild aufgerufen werden.

\lstset{language=C}
\begin{lstlisting}
#import <opencv2/core/core.hpp>
#import <opencv2/highgui/highgui.hpp>
#import <opencv2/nonfree/features2d.hpp>

using namespace cv;

int main () {
	const Mat image = imread(IMAGE_PATH, 0);
	SiftFeatureDetector detector;
	vector<KeyPoint> keypoints;
	
	detector.detect(input, keypoints);
}
\end{lstlisting}

TODO: Platzhalter Code-Listing, aber im Grunde funktioniert's so.

\section{Bag of Visual Words}

Das Bag of Visual Words Modell wurde direkt in C und cuda umgesetzt. Zur Erstellung und Interaktion eines Modells dient die Klasse BoVW und bietet hierfür vier Funktionen an. Die Funktion createCodebook(float **features) baut ein Codebook aus einer gegebenen Menge von Features auf und speichert dieses intern. Durch die Funktion saveCodebook(String path) und loadCodebook(String path) kann ein intern gespeichertes Codebook in eine Datei geschrieben werden bzw. von einer Datei eingelesen werden. Die letzte Funktion classify(String imagePath, int count) extrahiert lokale Features eines Bildes und berechnet die Ähnlichkeit der Visual Words. Es werden die ähnlichsten Bilder zurückgegeben. Die Anzahl der Ergebnisse kann durch den Parameter \textit{count} gesteuert werden. 
Da es sich bei der Berechnung der Cluster sowie der relativen Häufigkeiten um die rechenintensivsten Funktionen handelt, wurde diese parallelisiert.

\subsection{Paralleler k-means Algorithmus}

TODO

\subsection{Paralleles Histogramm}

Da die Zählung der Häufigkeit eines Visual Words in einem Dokument einem Histogramm entspricht, kann diese Aufgabe durch Grafikkarten und das \textit{Parallel Histogram} Muster stark parallelisiert werden. 

\begin{itemize}
	\item Histogramm (mit cuda Code) bereits in Grundlagen vorgestellt, hier auf Abweichungen / tatsächliche Implementierung eingehen? Oder stattdessen das Histogramm weniger detailliert in den Grundlagen behandeln? 
\end{itemize}

\section{Autoencoder}

Zur Implementierung des Autoencoders wurde TensorFlow verwendet. TensorFlow ist ein DeepLearning Framework und bietet Schnittstellen in diversen Sprachen an. Neben OpenCL wird auch Nvidias cuda unterstützt, sodass TensorFlow Programme automatisch von Grafikkarten profitieren können, ohne das der Entwickler diese explizit berücksichtigen muss. Für diese Umsetzung eines Autoencoders wurde Python und das Projekt \textit{libsdae-autoencoder-tensorflow}\footnote{https://github.com/rajarsheem/libsdae-autoencoder-tensorflow} von Rajar Sheem genutzt. Ein simpler Autoencoder mit einem HiddenLayer lässt sich wie folgt definieren:

\lstset{language=Python}
\begin{lstlisting}
from deepautoencoder import StackedAutoEncoder

model = StackedAutoEncoder(dims=[3], activations=['relu'], epoch=[1000], loss='rmse', lr=0.007, batch_size=50, print_step=100)
                       
result = model.fit_transform(x)
\end{lstlisting}

\begin{enumerate}
	\item TODO: erklären, tatsächliches Netz
	\item Referenzlayout
	\item Einlesen der Feature Vektoren etc.
	\item Speichern / Laden eines Netzes?
	\item Training
\end{enumerate}
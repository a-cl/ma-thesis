\chapter{Einleitung}

Gegenstand dieser Arbeit ist die Entwicklung eines maschinellen Lernverfahrens zur Kategorisierung von großen Bildmengen. Hintergrund hierfür ist, dass die Fakultät III der Hochschule Hannover (HsH) eine Datenbank mit mehreren Millionen Bildern besitzt, die ohne Information auf Herkunft oder Inhalt gespeichert wurden. Eine Analyse und Gewinnung von Informationen aus solch großen Datenmengen wird \textit{Data Mining} genannt. Die maschinellen Lernverfahren bilden ein Teilgebiet dieser Disziplin und viele der Konzepte gehen bereits auf die 40er Jahre zurück. Doch erst durch den enormen Anstieg der Rechenleistung und günstig gewordenen Speicher ist ein praktischer Einsatz interessant geworden. 
Ein wesentlicher Faktor dieser Verbreitung ist auch im Fortschritt des \textit{GPU (Graphics Processing Units)} Computing begründet. Hier wird die parallele Architektur der Grafikkarte genutzt, um mathematische Probleme um ein vielfaches schneller lösen zu können, als dies mit CPUs möglich wäre. Vor diesem Hintergrund und dem Fakt, dass es eine enorm große Menge an Daten zu verarbeiten gilt, ist das Modell auf eine Ausführung auf Grafikkarten ausgelegt. \newline
Zunächst skizziert der Abschnitt \enquote{Aufbau und Ablauf} die Struktur dieser Arbeit. Im Abschnitt Ziele wird dann formuliert, welchen Anforderungen das Modell genügen muss und welche Ergebnisse erwartet werden.

\section{Aufbau und Ablauf}

Das Grundlagenkapitel beginnt mit einer Einführung in digitale Bilder sowie die Erhebung und Kodierung von \enquote{interessanten} Informationen aus diesen, die sogenannten Features. Es wird definiert, wie Bilder und Features hier mathematisch notiert werden und Operationen, die im Weiteren von Bedeutung sind, auf diesen. Folgend werden die Wurzeln der hier eingesetzten Lernverfahren betrachtet. Dabei handelt es sich zum einen um die Familie der k-means-Algorithmen und zum anderen um die neuronalen Netze. Für die Ausführung dieser Algorithmen auf Grafikakrten wurde Nvidias CUDA Plattform gewählt. Daher folgt eine Einführung in das CUDA Ausführungs- und Programmiermodell. Letztes wird am Beispiel eines CUDA Programms zur Vektor Addition demonstriert.\newline
In der Analyse wird zu Beginn in das Themengebiet des \textit{Machine Learning} eingeführt. Es wird zwischen den verschiedenen Arten von Lernmethoden unterschieden und untersucht, welche Art von Verfahren für den vorliegenden Anwendungsfall geeignet ist. Da hieraus der Einsatz zweier unüberwachter Lernverfahren, zum einen der Autoencoder und zum anderen der Bag of Visual Words, resultiert, sind diese Gegenstand der beiden folgenden Abschnitte. Ein Autoencoder ist ein spezielles neuronales Netzwerk, dass hier zu Kompression von Daten genutzt wird. Das Bag of Visual Words Modell dient dann zur Gruppierung dieser Daten. Einer Erläuterung der Funktionsweise schließt eine Untersuchung der Parallelisierbarkeit des Algorithmus durch Grafikkarten an. Im letzten Abschnitt des Analysekapitels \enquote{Features} werden etablierte Verfahren zur Feature-Detektion und -Extraktion für Bilder betrachtet. Auf dieser Basis wird dann entschieden welcher Detektor bzw. Deskriptor im Weiteren verwendet wird. \newline
In der Konzeption wird zu Beginn ein Überblick über das gesamte Modell gegeben: Es werden die drei Phasen der Verarbeitung skizziert, sowie die Daten welche je Phase erwartet bzw. produziert werden. Anschließend werden die Funktionen und der Ablauf der einzelnen Phasen in je einem Abschnitt detailliert ausgearbeitet. Für den Entwurf eines Autoencoders wurde das Modell aus der Arbeit von Zhao \cite{aed2016} als Basis verwendet. Neben der Architektur des Netzes werden die von Zhao gewählten Hyperparameter näher beleuchtet. Im Abschnitt zum Bag of Visual Words wird dann das Erzeugen eines Modells aus Bild-Features, der Vergleich von Bildern durch das Modell und ein Persistenzmechanismus konzipiert. \newline
Die Implementierung behandelt in drei Abschnitten die konkrete Umsetzung der Extraktion von Features, der Komprimierung dieser durch einen Autoencoder und letztlich das Gruppieren durch einen Bag of Visual Words. Es wird gezeigt, wie die  rechenintensiven Operationen durch eine Grafikkarte stattfinden: Der Autoencoder ist in Googles Deep Learning Framework TensorFlow umgesetzt worden und profitiert automatisch von TensorFlows CUDA Schnittstelle. Der Clustering Algorithmus des Bag of Visual Words wurde das Projekt von Serban verwendet: Hier handelt es sich um einen k-means-Algorithmus in CUDA C. Insbesondere wird hier die Optimierung des Programms durch die Verwendung von CUDAs \textit{shared memory} veranschaulicht, sowie Einschränkungen aufgezeigt, die dies mit sich bringt.\newline
Das Kapitel \enquote{Evaluierung} stellt zunächst die verwendete Menge an Testdaten, die Bilder des \enquote{Caltech101}, vor und illustriert wie ein Experiment durchgeführt wird. Es wird die Qualität der Ergebnisse zwischen dem SIFT-Deskriptor und Zhaos Autoencoder-basierten Deskriptor für Bildfeatures verglichen und die Laufzeiten gegenübergestellt.

% Da für die Implementierung TensorFlow verwendet wird, wird hier zunächst eine Einführung in das Deep-Learning Framework gegeben und gezeigt, wie neuronale Netze abgebildet werden können.

\section{Ziele}

Ziel der Arbeit ist es, ein Verfahren zu entwickeln, die Bilder einer große Menge in eine vorgegebene Anzahl von Kategorien einzuteilen, um so semantische Informationen über die Bilder zu gewinnen. Hierbei leiten sich direkt Anforderungen an das Modell ab, doch andere Faktoren, wie der praktische Einsatz der Software und die Vergleichbarkeit der Ergebnisse sollen ebenfalls berücksichtigt werden. Konkret soll diese Arbeit folgende Ergebnisse liefern:

\begin{itemize}
	\item \textbf{Gruppierung der Bilddaten} Eine große Menge Bilder (mehrere Millionen) soll durch das Modell in annehmbarer Zeit gruppiert werden. Bei so vielen Datensätzen sind mehrere Stunden Laufzeit zu erwarten, Tage oder gar Wochen sind aber nicht akzeptabel. 
	\item \textbf{Verwendung von CUDA} Die zeitaufwendigsten Berechnungen sollen parallel durchgeführt werden. Da an der HsH und auch insbesondere der Fakultät III CUDA für parallele Berechnungen durch Grafikkarten verwendet wird, soll die Implementierung CUDA als technische Basis verwenden.
	\item \textbf{Bewertung der Ähnlichkeit von Bildern} Die Ähnlichkeit von Bildern soll durch das Modell bewertet werden können. Dabei wird kein \enquote{Label} (eine Bezeichnung / ein Name) für das Bild erzeugt. Ein Algorithmus kann unmöglich von sich aus lernen, dass Menschen die Abbildung einer Katze \enquote{Katze} nennen. Wenn das Modell aber zwei Bilder entgegennimmt, soll bewertet werden, wie ähnlich diese sich sind.
	\item \textbf{Vergleichbarkeit der Ergebnisse} Die Ergebnisse sollen prinzipiell mit denen anderen vergleichbar sein, in dem eine wissenschaftlich anerkannte Testmenge an Bilddaten verwendet wird.
\end{itemize}
